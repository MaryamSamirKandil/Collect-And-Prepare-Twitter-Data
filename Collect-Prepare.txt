getwd() ## Where am I ? "Default is Documents"
setwd("C:/Users/amani/Desktop/Workshop") ## Go to folder

####call libraries####

## To install libraries use

install.packages('sp')

library(twitteR)
library(RJSONIO)
library(bitops)
library(ROAuth) 
library(RCurl) 
library(stringi)
library(streamR) 
library(rJava) 
library(xlsxjars)
library(xlsx) 
library(readr)
library(rjson)
library(arabicStemR)
library(NLP)
library(tm)
library(sp)
library(RColorBrewer)
library(wordcloud)

####Authentication####
requestURL = "https://api.twitter.com/oauth/request_token"
accessURL = "https://api.twitter.com/oauth/access_token"
authURL = "https://api.twitter.com/oauth/authorize"

##Get keys from here https://apps.twitter.com/
consumerkey = "Your Consumer Key"
consumersecret = "Your Consumer Secret"

##Apply authenticate
my_oauth = OAuthFactory$new(consumerKey = consumerkey,
                            consumerSecret = consumersecret,
                            requestURL = requestURL,
                            accessURL = accessURL,
                            authURL = authURL)
my_oauth$handshake(curl=getCurlHandle())

##Save authentication
save(my_oauth, file = "myOauth.Rdata")
load("myOauth.Rdata")

####STREAMING DATA####

##Read streaming keywords
lexicon <- readLines("lexicon.csv")

##Convert string to unicode
keyword = stri_trans_nfkc(lexicon)

##Start streaming
filterStream(oauth=my_oauth, timeout = 60, track = keyword, file.name = "tweets.json") ## By seconds

##Save tweets as dataframe
data <- parseTweets("tweets.json", simplify = TRUE, legacy = TRUE)

##View(data)

write_excel_csv(data, "Streamed.csv", col_names = TRUE)

####CLEANING DATA####

##keywords don't reduce it
words2keep <- c("الله", "اللهم", "والله", "لله", "اللهم")

##rewrite all Alifs without Hamza
data$text <- fixAlifs(data$text)
##remove all non Arabic or English words
data$text <- cleanChars(data$text)
##remove all English letters
data$text <- cleanLatinChars(data$text)
##remove Arabic numbers
data$text <- removeArabicNumbers(data$text)
##remove Diacritics (tashkeel)
data$text <- removeDiacritics(data$text)
##remove farsi numbers
data$text <- removeFarsiNumbers(data$text)
##remove all numbers
data$text <- removeNumbers(data$text)

##replace ئ to ي and ؤ to و and ة to ه
data$text <- gsub("ئ", "ي", data$text)
data$text <- gsub("ؤ", "و", data$text)
data$text <- gsub("ة", "ه", data$text)

##reduce multi letters to one letter except words2keep
tmp1 <- paste0('(*UCP)\\b(?:',paste(collapse='|',words2keep),')\\b(*SKIP)(*F)|(\\p{L})\\1+')
data$text <- gsub(tmp1, '\\1',data$text, perl=TRUE)

##remove any one letter alone
data$text <- gsub(" *\\b[ا | ب | ت | ث | ج | ح | خ | د | ذ | ر | ز | س | ش | ص | ض | ط | ظ | ع | غ | ف | ق | ك | ل | م | ن | ه | و | ي | ى | ء]{1}\\b *", " ", data$text)

##remove newlines
data$text <- gsub("\\n", " ", data$text)
##remove tabs
data$text <- gsub("\\t", " ", data$text)
##remove arabic letter tatwil (ـ)
data$text <- gsub("ـ", "", data$text)
##remove all punctuations except #
data$text <- gsub("([#])|[[:punct:]]", "\\1 ", data$text)

##reduce spaces to one space
data$text <- gsub("([[:space:]])\\1+", "\\1", data$text)
##remove begin and end spaces
data$text <- gsub("^\\s+|\\s+$", "", data$text)


write_excel_csv(data, "Cleaned.csv", col_names = TRUE)


####Spam Filtering####


##Keep keywords
keep <- c( "الملك سلمان", "الملك عبدالله", "الملك فهد", "الملك خالد", "الملك عبدالعزيز", "الملك فيصل", "الملك سعود", "خريص", "العليا", "الجسر المعلق", "علي بن ابي طالب", "الامير سعد بن عبدالرحمن الاول", "الامير محمد بن سعد", "الشفا", "الامير نايف", "انس بن مالك", "الامير ماجد",
           
           "الثمامه" , "الدايري الجنوبي" , "الدايري الغربي" , "الدايري الشرقي" , "الدايري الشمالي" , "الامام فيصل" , "ديراب" , "'طريق مكه" , "عثمان بن عفان" , "ابو بكر" , "طريق الدمام", "الامير سطام", "شارع الستين", "صلاح الدين", "شارع الثلاثين", "الامير سلطان", "شارع الخزان")

##spam keywords
spam <- c( "عروض", "عرض", "نقل", "دراسات", "الدراسات", "جده", "الوظايف", "الوظائف", "شركه", "شركة", "عقار", "عقارات", "مستشفى", "فندق", "مصنع", "سالب", "انيك", "نيك", "سوالب", "عاملات", "حايل", "الشرقيه", "الدمام", "تحرير", "الديوثين", "ديوث", "العماله", "العمالة", "مبادل", "مطعم", "مطاعم", "القانوني", "مستشار", "المستشار", "اجازه", "اجازة", "الطبقه", "الطبقة", "الجهات", "الخير", "ذكريات", "تنظيف", "العاب", "ألعاب", "منزلي", "منزليه", "منزلية", "صيدليات", "سياسي", "جلسه", "جلسة", "شعر", "ابيات",
           
           "للبيع", "زياره", "مكتب", "طلب", "سكري", "فاخر", "ملكي", "المؤسسه", "المؤسسة", "لاعب", "القدم", "المعرض ", "معرض", "العائلي", "اكاديمية", "العملاء", "المحكمة", "محل", "للتقبيل", "مشاريع", "التدريس", "الكليه", "بريده", "حدث", "التقديم", "معارض", "العسل", "رحله", "الصفوف", "رسول", "حديث", "البحرين", "اسعار", "المشاركه", "سوق", "مخطط", "موجب", "وكيل", "مراتب", "غسيل", "عود", "اسهم", "سناب", "توصيل", "اليد", "مدير", "ريمكس", "رسمي", 
           
           "غرف", "غرفه", "غرفة", "مجاهدين", "مندوب", "شقه", "تطوير", "السلطات", "الاستاذ", "الاستاذه", "الاستاذة", "الخبر", "الدرجه", "المكونات", "عطر", "التعلم", "صحيح", "قطر", "البيك" , "الجنه" , "الشريفين" , "عطر", "الواتس" , "الواتساب" ,"الكتب", "تسجيل", "ركز", "ولي", "متجر", "نبارك", "المناصب" , "منتخب" , "الخدمات", "مطلوب", "الاستسلام", "كفايات", "قرار", "اجنحه", "ترشح", "فرقه", "كتاب", "جثمان", "الدوله", "حلويات", "الحرية", "المزاحمية", "تكريم" ,"بوفيه" ,"الكلمه", "التخرج" ,"صيانه" , 
           
           "العراق" , "المصالح" ,"مشترك" ,"السودان" ,"الاعلاميين" ,"دوري", "الاعلامي" ,"التوحيد" ,"الجبيل" , "عضو", "جلسات","الطبقات","العالمي" , "اشواقي" , "شعار" ,"مؤتمر" , "المسلسل" , "خيال" , "قريا" , "الحب" ,"اخلاقيه" , "لحجز" , "بنود" , "الدستوريه","لجنه", "اماراتي", "حسابي", "العشق", "كوفي", " الاوروبي", "عياده", "عيادات ", "دهان" ,"جراحه" ,"استشاري", "لجنه", "جسمك", "اعلامي", "البث" ,"بث", "البواسل", "الاستراحه" ,"مظلات" ,"القبه", "العناية", "العنايه",
           
           "عسير", "الرس", "المقدسه", "الدلم" , "الحديقه", "الحوثي" , "حوثي" ,"حبايب" ,"يعتقد" ,"سكس" ,"المملكه ", "بارتي", "حلاق", "حمله" ,"تعيش" ,"متخلف" ,"سداد" ,"قروض", "مبادره" ,"وصفه" , "شاليهات" ,"قضيه" , "المجلس" , "كواليس" ,"الشهيد" , "نتشرف" , "دورات " , "حلوه " ,"الوطن" ,"مدينه", "مدينة", "دبي", "الفتنه", "الفتنة", "رصيد" , "الطايف" , "مجاني" ,"حفل" ,"دوره", "اعلان", "ترامب" , "ترمب" ,"صحيفه" ,"القاهره" ,"مسلسل" , "مهارات" , "حروب" , "المكارم" , "البطل" , "السوالف" , "خاص" , "وزير" , "خصم",
           
           "قناه" ,"ايران" , "صدى" , "مص" ,"الشوق" ,"فلوس" , "اعلن" ,"مسابقه" ,"خانت" , "سكن" , "جنود" , "ابحث" , "مراهقه", "الاسلوب" ,"الماده" ,"تاجير" ,"فوايد", "كحيلان" , "هياط" , "الحيوانات" , "الفروسيه" ,"محافظه" , "المصريه" , "بطاقه" , "مبيعات" , "الحكومه", "تركيب", "مذهب", "فروع", "مشروع", "المشاريع", "تخصصات", "تعليم", "المؤهلات", "المؤهلة", "الكره", "كره", "الكرة", "كرة", "جاد", "معسل " , "رصيدك" , "فحل" , "فحول" , "الصحوه" , "ازغب" , "موزه" , "حمد" , "طيز" , "تميم" ,
           
           "يغتصبني" , "مشتهي" , "مشتهيه" , "تحتي" , "كسمك" , "كس" , "الباحه" , "الدوادمي" , "وادي الدواسر" , "زب" , "رصيدك" , "مخرج" ,"الخرج", "المطار" , "الدمام" , "الكويت")


##delete all rows with no Keep keywords
text <- data[grepl(paste(Keep, collapse="|"), data$text),]
data <- as.data.frame(text)

##delete all rows with spam keywords
data <- data[!grepl(paste(spam, collapse="|"), data$text),]

##delete all rows with more than four hashtags
data <- data[sapply(strsplit(as.character(data$text),"#"),length)<4,]
##remove remaining #
data$text <- gsub("#", " ", data$text)


##delete empty rows
data <- data[!grepl("\u009f", data$text),]
data[data == ""] <- NA
data <- data[grepl("", data$text),]

##reduce spaces to one space
data$text <- gsub("([[:space:]])\\1+", "\\1", data$text)
##remove begin and end spaces
data$text <- gsub("^\\s+|\\s+$", "", data$text)

##delete duplicated rows
data <- data[!duplicated(data$text),]
##delete rows with less than two words
data <- data[sapply(strsplit(as.character(data$text)," "),length)>1,]

write_excel_csv(data, "Filtered.csv", col_names = TRUE)


####Removing StopWords####


##stopWords keywords
stopWords <- c( "ابتدا", "اجل", "اجمع", "اخ", "اخذ", "اذ", "اذا", "اف", "اقل", "اكثر", "الا", "التي", "الذي", "الذين", "اللي", "الورا", "الى", "اليك", "ام", "اما", "امام", "امامك", "امين", "ان", "انا", "انت", "انتم", "انتو", "انك", "انما", "اننا", "انه", "انها", "انهم", "انهما", "اني", "اه", "اها", "او", "اوه", "ايضا", "اين", "ايه", "اولا", "اي", "ايا", "اينما", "باتجاه", "بالرغم", "بان", "بانهم", "بجانب", "بحيث", "بدون", "بذلك", "بس", "بسبب", "بضع", "بعد", "بعض", "بفضل", "بك", "بكل", "بل", "بله", "بلى", "بما", "بماذا", "بمن", "بنا", "به", "بها", "بهم", "بي",
                
                "بين", "بينكم", "بينما", "بينهم", "بينهما", "تبدل", "تجاه", "تحت", "تلقا", "تلك", "تلكم", "ثم", "جعل", "جميع", "حار", "حتى", "حسب", "حول", "حيث", "خلال", "دون", "دونك", "ذا", "ذات", "ذاك", "ذلك", "ذه", "ذي", "ذيك", "راح", "رب", "رجع", "رغم", "سبحان", "سوف", "سوى", "شبه", "صار", "صه", "عاد", "عامه", "عدا", "عسى", "عل", "علق", "على", "عليك", "عليكم", "علينا", "عليه", "عليها", "عما", "عن", "عنا", "عند", "عندما", "عندنا", "عنك", "عنه", "عنها", "عنهم", "عنهما", "غير", "فاذا", "فانا", "فانهم", "فقط", "فكل", "فلان", "فلم",
                
                "فلما", "فما", "فمن", "فهذا", "فهل", "فهم", "فهو", "فهولا", "فو", "فوق", "في", "فيك", "فيكم", "فيم", "فيما", "فيه", "فيها", "فيهم", "قام", "قبل", "قد", "قط", "قلما", "كاد", "كان", "كانما", "كذا", "كذلك", "كل", "كلا", "كلما", "كم", "كما", "كي", "كيف", "كيفما", "لا", "لان", "لانه", "لانها", "لانهم", "لدى", "لذا", "لذلك", "لست", "لعل", "لعمر", "لقد", "لك", "لكل", "لكم", "لكما", "لكن", "لكنما", "لكنه", "لكنها", "لكي", "لم", "لما", "لماذا", "لمن", "لن", "لنا", "له", "لها", "لهذا", "لهم", "لو", "لولا", "لي", "ليت", "ليس", "ليست", "لين", "ما", "مادام", "ماذا", "مازال",
                
                "متى", "مثل", "مذ", "مع", "معه", "معها", "معهم", "مكانك", "مما", "ممن", "من", "منا", "منذ", "منك", "منكم", "منهم", "منهما", "مهما", "نحن", "نحو", "نعم", "نفس", "ها", "هاك", "هذا", "هذان", "هذه", "هذولا", "هذي", "هكذا", "هل", "هلا", "هم", "هما", "هن", "هنا", "هناك", "هو", "هولا", "هي", "هيا", "و", "وا", "واذ", "واذا", "وان", "واها", "ورا", "وراك", "وكم", "ولا", "ولسوف", "ولكن", "ولم", "ولو", "وما", "ومن", "وهل", "وهم", "وي", "يا", "وفي", "وهو", "ي", "مافيه", "مافي", "وش", "شي", "ياخي", "هاذا", "وه", "هنا", "ماعدا", "ما عدا", "وقد",
                
                "وكم", "تراك", "ياخو", "خبر", "مو", "مش")


stopWords <- data.frame(stopWords)

##data$text
##copy text to temp dataframe
tmp <- data$text
##remove stopwords
tmp <- removeWords(tmp, stopWords$stopWords)
##move temp have new text to original file
data$text <- tmp
##remove prefixes
##rowNUM <- 1
##while((is.na(data$text[rowNUM])) != TRUE)
##{
##  data$text[rowNUM] <- removePrefixes(data$text[rowNUM])
##  rowNUM <- rowNUM + 1
##}

##reduce spaces to one space
data$text <- gsub("([[:space:]])\\1+", "\\1", data$text)
##remove begin and end spaces
data$text <- gsub("^\\s+|\\s+$", "", data$text)

write_excel_csv(data, "StopWords Removed.csv", col_names = TRUE)

##To read file
##csvFile <- read.csv(file = "Streamed.csv", header = FALSE, stringsAsFactors=FALSE, encoding = "UTF-8")

##To make wordcloud
Corpus = Corpus(VectorSource(data$text))
wordcloud(Corpus,max.words =100,random.color = TRUE,random.order=FALSE)
